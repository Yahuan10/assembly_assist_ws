#!/usr/bin/env python
# filepath: /Users/yujiangtao/my_project/PJ_Auto/src/schledluer/src/script.py

import rospy
import cv2
import numpy as np
from std_msgs.msg import String
from geometry_msgs.msg import Pose, PoseStamped
from moveit_msgs.msg import DisplayTrajectory
from trajectory_msgs.msg import JointTrajectory
import threading
import time
from datetime import datetime, timedelta
import tf2_ros
import tf2_geometry_msgs

class TrajectoryPredictor:
    def __init__(self, h_matrix=None):
        rospy.init_node('trajectory_predictor', anonymous=True)
        
        # ğŸ”§ ä½¿ç”¨æ ‡å®šåçš„HçŸ©é˜µ
        if h_matrix is not None:
            self.h_matrix = h_matrix
        else:
            # é»˜è®¤HçŸ©é˜µï¼ˆéœ€è¦æ›¿æ¢ä¸ºä½ çš„å®é™…æ ‡å®šç»“æœï¼‰
            self.h_matrix = np.array([
                [800.0,  0.0,   512.0],
                [0.0,    -800.0, 384.0],
                [0.0,    0.0,    1.0]
            ], dtype=np.float32)
        
        # ğŸ”§ ç”»å¸ƒå¤§å°è®¾ç½®ä¸º1024x768
        self.window_width = 1024
        self.window_height = 768
        
        # å½“å‰çŠ¶æ€
        self.current_state = "Start"
        self.current_tcp_pose = None
        self.target_pose = None
        self.trajectory_points = []
        self.interpolated_trajectory = []
        
        # ä»schedulerä»£ç ä¸­æå–çš„å…³é”®ä½ç½®ç‚¹
        self.key_positions = self.load_key_positions()
        
        # çŠ¶æ€è½¨è¿¹æ˜ å°„
        self.state_trajectories = self.create_state_trajectory_mapping()
        
        # æ˜¾ç¤ºè®¾ç½®
        self.window_name = "æœºæ¢°è‡‚è½¨è¿¹é¢„æµ‹å’Œæ–¹å‘æŒ‡ç¤º"
        
        # é¢œè‰²è®¾ç½®
        self.colors = {
            'background': (40, 40, 40),
            'current_pos': (0, 255, 0),        # ç»¿è‰² - å½“å‰ä½ç½®
            'target_pos': (0, 0, 255),         # çº¢è‰² - ç›®æ ‡ä½ç½®
            'predicted_path': (255, 165, 0),   # æ©™è‰² - é¢„æµ‹è·¯å¾„
            'direction_arrow': (0, 255, 255),  # é»„è‰² - æ–¹å‘ç®­å¤´
            'text_white': (255, 255, 255),
            'grid': (80, 80, 80),
            'workspace_boundary': (128, 128, 128)  # ç°è‰² - å·¥ä½œç©ºé—´è¾¹ç•Œ
        }
        
        self.setup_ros_communication()
        self.start_prediction_thread()
        self.start_display()

    def set_h_matrix(self, h_matrix):
        """ğŸ”§ è®¾ç½®æ ‡å®šåçš„HçŸ©é˜µ"""
        self.h_matrix = h_matrix.astype(np.float32)
        rospy.loginfo("HçŸ©é˜µå·²æ›´æ–°")

    def tcp_to_screen_coords(self, tcp_position):
        """ğŸš€ ä½¿ç”¨HçŸ©é˜µå°†TCPåæ ‡è½¬æ¢ä¸ºå±å¹•åæ ‡"""
        try:
            # å°†TCPåæ ‡è½¬æ¢ä¸ºé½æ¬¡åæ ‡ [x, y, 1]
            tcp_homogeneous = np.array([
                tcp_position[0],  # Xåæ ‡
                tcp_position[1],  # Yåæ ‡  
                1.0               # é½æ¬¡åæ ‡
            ], dtype=np.float32)
            
            # åº”ç”¨HçŸ©é˜µå˜æ¢
            screen_homogeneous = self.h_matrix @ tcp_homogeneous
            
            # è½¬æ¢å›éé½æ¬¡åæ ‡
            if screen_homogeneous[2] != 0:
                screen_x = int(screen_homogeneous[0] / screen_homogeneous[2])
                screen_y = int(screen_homogeneous[1] / screen_homogeneous[2])
            else:
                screen_x, screen_y = 0, 0
            
            # é™åˆ¶åœ¨ç”»å¸ƒèŒƒå›´å†…
            screen_x = max(0, min(screen_x, self.window_width - 1))
            screen_y = max(0, min(screen_y, self.window_height - 1))
            
            return (screen_x, screen_y)
            
        except Exception as e:
            rospy.logwarn(f"TCPåæ ‡è½¬æ¢é”™è¯¯: {e}")
            return (self.window_width // 2, self.window_height // 2)

    def screen_to_tcp_coords(self, screen_x, screen_y):
        """ğŸ”§ å°†å±å¹•åæ ‡è½¬æ¢å›TCPåæ ‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        try:
            # ä½¿ç”¨HçŸ©é˜µçš„é€†çŸ©é˜µ
            h_inv = np.linalg.inv(self.h_matrix)
            
            screen_homogeneous = np.array([screen_x, screen_y, 1.0], dtype=np.float32)
            tcp_homogeneous = h_inv @ screen_homogeneous
            
            if tcp_homogeneous[2] != 0:
                tcp_x = tcp_homogeneous[0] / tcp_homogeneous[2]
                tcp_y = tcp_homogeneous[1] / tcp_homogeneous[2]
            else:
                tcp_x, tcp_y = 0.0, 0.0
                
            return (tcp_x, tcp_y)
            
        except Exception as e:
            rospy.logwarn(f"å±å¹•åæ ‡è½¬æ¢é”™è¯¯: {e}")
            return (0.0, 0.0)

    def load_key_positions(self):
        """ä»schedulerä»£ç ä¸­æå–å…³é”®ä½ç½®ç‚¹"""
        return {
            # ç”µæœºä½ç½® (16ä¸ª)
            'motors': [
                [0.263, 0.115, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.263, 0.068, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.263, 0.021, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.263, -0.026, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.343, 0.115, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.343, 0.068, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.343, 0.021, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.343, -0.026, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.423, 0.115, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.423, 0.068, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.423, 0.021, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.423, -0.026, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.505, 0.115, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.505, 0.068, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.505, 0.021, 0.194, 0.018, 0.999, -0.010, 0.009],
                [0.505, -0.026, 0.194, 0.018, 0.999, -0.010, 0.009],
            ],
            
            # è¿‡æ¸¡ç‚¹
            'transitions': {
                'over_motor': [0.327, 0.0, 0.355, -0.003, -0.999, 0.002, 0.0007],
                'over_gb0_1': [0.439, -0.271, 0.215, -0.001, -0.696, 0.718, 0.001],
                'over_gb0_2': [0.439, -0.210, 0.300, -0.001, -0.696, 0.718, 0.001],
                'over_gb1_1': [0.438, -0.331, 0.391, 0.703, 0.710, 0.002, 0.005],
                'over_gb1_2': [0.438, -0.460, 0.391, 0.703, 0.710, 0.002, 0.005],
                'over_gb1_3': [0.438, -0.460, 0.354, 0.703, 0.710, 0.002, 0.005],
            },
            
            # PCBä½ç½®
            'pcb1': [
                [0.631, -0.139, 0.168, 0.703, 0.710, 0.002, 0.005],
                [0.686, -0.139, 0.168, 0.703, 0.710, 0.002, 0.005],
                [0.741, -0.139, 0.168, 0.703, 0.710, 0.002, 0.005],
                [0.796, -0.139, 0.168, 0.703, 0.710, 0.002, 0.005],
            ],
            
            # äººç±»äº¤æ¥ä½ç½®
            'handover': [0.011, -0.407, 0.434, 0.659, 0.133, -0.040, 0.738],
            
            # ç”µæ± ä½ç½®
            'battery': [
                [0.606, -0.019, 0.154, 0.999, 0.012, -0.012, 0.022],
                [0.606, 0.103, 0.154, 0.999, 0.012, -0.012, 0.022],
                [0.707, -0.019, 0.154, 0.999, 0.012, -0.012, 0.022],
                [0.707, 0.101, 0.154, 0.999, 0.012, -0.012, 0.022],
            ]
        }

    def create_state_trajectory_mapping(self):
        """åˆ›å»ºçŠ¶æ€åˆ°è½¨è¿¹çš„æ˜ å°„"""
        return {
            'MPickUp': {
                'sequence': [
                    {'type': 'joint', 'description': 'ç§»åŠ¨åˆ°å‡†å¤‡ä½ç½®'},
                    {'type': 'move', 'target': 'transitions.over_motor', 'description': 'ç§»åŠ¨åˆ°ç”µæœºä¸Šæ–¹'},
                    {'type': 'pick', 'target': 'motors.0', 'description': 'æŠ“å–ç”µæœº'},
                    {'type': 'joint', 'description': 'ç§»åŠ¨åˆ°äº¤æ¥å‡†å¤‡ä½ç½®'},
                ],
                'duration': 14.0
            },
            'MHoldHD': {
                'sequence': [
                    {'type': 'move', 'target': 'handover', 'description': 'ç§»åŠ¨åˆ°äº¤æ¥ä½ç½®'},
                    {'type': 'wait', 'duration': 8.0, 'description': 'ç­‰å¾…äººç±»æ¥æ”¶'},
                    {'type': 'joint', 'description': 'è¿”å›å®‰å…¨ä½ç½®'},
                ],
                'duration': 18.0
            },
            'MPositioning': {
                'sequence': [
                    {'type': 'move', 'target': 'transitions.over_gb0_1', 'description': 'ç§»åŠ¨åˆ°å®šä½åŒºåŸŸ'},
                    {'type': 'gripper', 'action': 'open', 'description': 'é‡Šæ”¾ç”µæœº'},
                    {'type': 'move', 'target': 'transitions.over_gb0_2', 'description': 'ç§»åŠ¨åˆ°å®‰å…¨ä½ç½®'},
                ],
                'duration': 5.0
            },
            'PCB1PickUpAndPositioning': {
                'sequence': [
                    {'type': 'joint', 'description': 'ç§»åŠ¨åˆ°PCB1åŒºåŸŸ'},
                    {'type': 'pick', 'target': 'pcb1.0', 'description': 'æŠ“å–PCB1'},
                    {'type': 'move', 'target': 'transitions.over_gb1_1', 'description': 'è¿‡æ¸¡ç‚¹1'},
                    {'type': 'move', 'target': 'transitions.over_gb1_2', 'description': 'è¿‡æ¸¡ç‚¹2'},
                    {'type': 'move', 'target': 'transitions.over_gb1_3', 'description': 'å®šä½ç‚¹'},
                    {'type': 'gripper', 'action': 'open', 'description': 'æ”¾ç½®PCB1'},
                ],
                'duration': 13.0
            }
        }

    def setup_ros_communication(self):
        """è®¾ç½®ROSé€šä¿¡"""
        # è®¢é˜…å½“å‰TCPä½ç½®
        self.tcp_subscriber = rospy.Subscriber('/move_group/display_planned_path', 
                                              DisplayTrajectory, 
                                              self.trajectory_callback)
        
        # è®¢é˜…å½“å‰TCP pose
        self.pose_subscriber = rospy.Subscriber('/ur5/tcp_pose', 
                                               Pose, 
                                               self.tcp_pose_callback)
        
        # è®¢é˜…SMACHçŠ¶æ€
        self.state_subscriber = rospy.Subscriber('/smach/container_status', 
                                                String, 
                                                self.state_callback)

    def trajectory_callback(self, msg):
        """è½¨è¿¹è§„åˆ’å›è°ƒ - è·å–MoveItè§„åˆ’çš„è½¨è¿¹"""
        if msg.trajectory and len(msg.trajectory) > 0:
            trajectory = msg.trajectory[0].joint_trajectory
            self.trajectory_points = self.convert_joint_trajectory_to_cartesian(trajectory)

    def tcp_pose_callback(self, msg):
        """TCPä½ç½®å›è°ƒ"""
        self.current_tcp_pose = [
            msg.position.x, msg.position.y, msg.position.z,
            msg.orientation.x, msg.orientation.y, msg.orientation.z, msg.orientation.w
        ]

    def state_callback(self, msg):
        """çŠ¶æ€å˜åŒ–å›è°ƒ"""
        new_state = msg.data.strip()
        if new_state != self.current_state:
            self.current_state = new_state
            self.predict_next_trajectory()

    def convert_joint_trajectory_to_cartesian(self, joint_trajectory):
        """å°†å…³èŠ‚è½¨è¿¹è½¬æ¢ä¸ºç¬›å¡å°”è½¨è¿¹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        cartesian_points = []
        
        if len(joint_trajectory.points) > 0:
            start_pos = self.current_tcp_pose if self.current_tcp_pose else [0, 0, 0, 0, 0, 0, 1]
            end_pos = self.target_pose if self.target_pose else start_pos
            
            num_points = len(joint_trajectory.points)
            for i in range(num_points):
                t = i / (num_points - 1) if num_points > 1 else 0
                interpolated_pos = [
                    start_pos[j] + t * (end_pos[j] - start_pos[j]) for j in range(3)
                ]
                interpolated_pos.extend([0, 0, 0, 1])
                cartesian_points.append(interpolated_pos)
        
        return cartesian_points

    def predict_next_trajectory(self):
        """é¢„æµ‹ä¸‹ä¸€æ®µè½¨è¿¹"""
        if self.current_state not in self.state_trajectories:
            return
        
        state_info = self.state_trajectories[self.current_state]
        sequence = state_info['sequence']
        
        self.interpolated_trajectory = []
        current_pos = self.current_tcp_pose if self.current_tcp_pose else [0, 0, 0, 0, 0, 0, 1]
        
        for step in sequence:
            if step['type'] == 'move' or step['type'] == 'pick':
                target_key = step.get('target', '')
                target_pos = self.get_position_from_key(target_key)
                
                if target_pos:
                    interpolated_points = self.interpolate_trajectory(current_pos, target_pos, 20)
                    for point in interpolated_points:
                        self.interpolated_trajectory.append({
                            'position': point[:3],
                            'orientation': point[3:7],
                            'description': step['description'],
                            'type': step['type']
                        })
                    current_pos = target_pos

    def get_position_from_key(self, key):
        """ä»å…³é”®å­—è·å–ä½ç½®"""
        if not key:
            return None
        
        keys = key.split('.')
        data = self.key_positions
        
        try:
            for k in keys:
                if k.isdigit():
                    data = data[int(k)]
                else:
                    data = data[k]
            return data
        except (KeyError, IndexError, TypeError):
            return None

    def interpolate_trajectory(self, start_pos, end_pos, num_points):
        """åœ¨ä¸¤ç‚¹é—´æ’å€¼ç”Ÿæˆè½¨è¿¹"""
        trajectory = []
        for i in range(num_points):
            t = i / (num_points - 1) if num_points > 1 else 0
            interpolated = [
                start_pos[j] + t * (end_pos[j] - start_pos[j]) for j in range(len(start_pos))
            ]
            trajectory.append(interpolated)
        return trajectory

    def start_prediction_thread(self):
        """å¯åŠ¨é¢„æµ‹çº¿ç¨‹"""
        def prediction_loop():
            rate = rospy.Rate(5)
            while not rospy.is_shutdown():
                if self.current_state != "Start":
                    self.predict_next_trajectory()
                rate.sleep()
        
        thread = threading.Thread(target=prediction_loop)
        thread.daemon = True
        thread.start()

    def create_display_image(self):
        """åˆ›å»ºæ˜¾ç¤ºå›¾åƒ"""
        img = np.full((self.window_height, self.window_width, 3), 
                      self.colors['background'], dtype=np.uint8)
        
        # ç»˜åˆ¶å„ä¸ªéƒ¨åˆ†
        self.draw_title(img)
        self.draw_workspace_boundary(img)
        self.draw_trajectory_overlay(img)
        self.draw_direction_indicators(img)
        self.draw_next_targets_overlay(img)
        self.draw_coordinate_info(img)
        
        return img

    def draw_title(self, img):
        """ç»˜åˆ¶æ ‡é¢˜"""
        title = f"æœºæ¢°è‡‚è½¨è¿¹é¢„æµ‹ - å½“å‰çŠ¶æ€: {self.current_state}"
        cv2.putText(img, title, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                   0.8, self.colors['text_white'], 2)

    def draw_workspace_boundary(self, img):
        """ğŸ”§ ç»˜åˆ¶å·¥ä½œç©ºé—´è¾¹ç•Œ"""
        # å®šä¹‰å·¥ä½œç©ºé—´çš„TCPåæ ‡è¾¹ç•Œ
        workspace_tcp_coords = [
            [-0.5, -0.7],  # å·¦ä¸‹è§’
            [0.8, -0.7],   # å³ä¸‹è§’  
            [0.8, 0.5],    # å³ä¸Šè§’
            [-0.5, 0.5],   # å·¦ä¸Šè§’
        ]
        
        # è½¬æ¢ä¸ºå±å¹•åæ ‡
        screen_coords = []
        for tcp_coord in workspace_tcp_coords:
            screen_coord = self.tcp_to_screen_coords(tcp_coord)
            screen_coords.append(screen_coord)
        
        # ç»˜åˆ¶å·¥ä½œç©ºé—´è¾¹ç•Œ
        if len(screen_coords) >= 4:
            pts = np.array(screen_coords, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(img, [pts], True, self.colors['workspace_boundary'], 2)
            
            # æ·»åŠ æ ‡ç­¾
            cv2.putText(img, "å·¥ä½œç©ºé—´", (screen_coords[0][0], screen_coords[0][1] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['workspace_boundary'], 1)

    def draw_trajectory_overlay(self, img):
        """ğŸš€ ç»˜åˆ¶è½¨è¿¹è¦†ç›–å±‚ï¼ˆç›´æ¥åœ¨1024x768ç”»å¸ƒä¸Šï¼‰"""
        # ç»˜åˆ¶å½“å‰ä½ç½®
        if self.current_tcp_pose:
            current_screen = self.tcp_to_screen_coords(self.current_tcp_pose[:2])
            cv2.circle(img, current_screen, 12, self.colors['current_pos'], -1)
            cv2.circle(img, current_screen, 15, self.colors['text_white'], 2)
            cv2.putText(img, "å½“å‰ä½ç½®", (current_screen[0] + 20, current_screen[1] - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['current_pos'], 2)
        
        # ç»˜åˆ¶é¢„æµ‹è½¨è¿¹
        prev_screen = None
        for i, point in enumerate(self.interpolated_trajectory):
            screen_pos = self.tcp_to_screen_coords(point['position'][:2])
            
            # ç»˜åˆ¶è½¨è¿¹çº¿
            if prev_screen is not None:
                cv2.line(img, prev_screen, screen_pos, self.colors['predicted_path'], 3)
            
            # ç»˜åˆ¶è½¨è¿¹ç‚¹
            cv2.circle(img, screen_pos, 5, self.colors['predicted_path'], -1)
            
            # æ¯10ä¸ªç‚¹æ ‡æ³¨ä¸€ä¸ªæè¿°
            if i % 10 == 0 and point.get('description'):
                cv2.putText(img, point['description'][:8], 
                           (screen_pos[0] + 10, screen_pos[1] + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, self.colors['text_white'], 1)
            
            prev_screen = screen_pos

    def draw_direction_indicators(self, img):
        """ç»˜åˆ¶æ–¹å‘æŒ‡ç¤ºç®­å¤´"""
        if len(self.interpolated_trajectory) < 2:
            return
        
        # ç»˜åˆ¶æ–¹å‘ç®­å¤´ï¼ˆæ¯8ä¸ªç‚¹ç»˜åˆ¶ä¸€ä¸ªç®­å¤´ï¼‰
        for i in range(0, len(self.interpolated_trajectory) - 1, 8):
            current_point = self.interpolated_trajectory[i]['position']
            next_point = self.interpolated_trajectory[i + 1]['position']
            
            # è½¬æ¢åˆ°å±å¹•åæ ‡
            current_screen = self.tcp_to_screen_coords(current_point[:2])
            next_screen = self.tcp_to_screen_coords(next_point[:2])
            
            # è®¡ç®—æ–¹å‘å‘é‡
            direction = np.array(next_screen) - np.array(current_screen)
            length = np.linalg.norm(direction)
            
            if length > 10:  # åªç»˜åˆ¶è¶³å¤Ÿé•¿çš„ç®­å¤´
                direction = direction / length * 30
                arrow_end = tuple((np.array(current_screen) + direction).astype(int))
                cv2.arrowedLine(img, current_screen, arrow_end, 
                               self.colors['direction_arrow'], 3, tipLength=0.4)

    def draw_next_targets_overlay(self, img):
        """ç»˜åˆ¶æ¥ä¸‹æ¥çš„ç›®æ ‡ä½ç½®è¦†ç›–å±‚"""
        # åœ¨å³ä¾§æ˜¾ç¤ºç›®æ ‡ä¿¡æ¯
        info_x = self.window_width - 350
        info_y = 80
        
        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = img.copy()
        cv2.rectangle(overlay, (info_x - 10, info_y - 10), 
                     (self.window_width - 10, info_y + 300), 
                     (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, img, 0.3, 0, img)
        
        cv2.putText(img, "æ¥ä¸‹æ¥çš„ç›®æ ‡:", (info_x, info_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.colors['text_white'], 2)
        
        # æ˜¾ç¤ºæ¥ä¸‹æ¥çš„ç›®æ ‡
        y_offset = 30
        shown_targets = set()
        
        for i, point in enumerate(self.interpolated_trajectory[:50]):
            if point['type'] in ['move', 'pick'] and point['description'] not in shown_targets:
                target_text = f"â€¢ {point['description']}"
                cv2.putText(img, target_text, (info_x, info_y + y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['predicted_path'], 1)
                
                # æ˜¾ç¤ºåæ ‡
                pos_text = f"  [{point['position'][0]:.3f}, {point['position'][1]:.3f}]"
                cv2.putText(img, pos_text, (info_x, info_y + y_offset + 15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, self.colors['text_white'], 1)
                
                # åœ¨ä¸»è§†å›¾ä¸­æ ‡å‡ºç›®æ ‡ä½ç½®
                target_screen = self.tcp_to_screen_coords(point['position'][:2])
                cv2.circle(img, target_screen, 8, self.colors['target_pos'], 2)
                cv2.putText(img, str(len(shown_targets) + 1), 
                           (target_screen[0] - 5, target_screen[1] + 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['target_pos'], 1)
                
                shown_targets.add(point['description'])
                y_offset += 40
                
                if len(shown_targets) >= 6:
                    break

    def draw_coordinate_info(self, img):
        """ğŸ”§ ç»˜åˆ¶åæ ‡ä¿¡æ¯"""
        info_y = self.window_height - 80
        
        # HçŸ©é˜µä¿¡æ¯
        h_info = f"HçŸ©é˜µ: [{self.h_matrix[0,0]:.1f}, {self.h_matrix[0,1]:.1f}, {self.h_matrix[0,2]:.1f}]"
        cv2.putText(img, h_info, (20, info_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['text_white'], 1)
        
        # å½“å‰TCPåæ ‡
        if self.current_tcp_pose:
            tcp_info = f"TCP: [{self.current_tcp_pose[0]:.3f}, {self.current_tcp_pose[1]:.3f}, {self.current_tcp_pose[2]:.3f}]"
            cv2.putText(img, tcp_info, (20, info_y + 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['current_pos'], 1)
            
            # å¯¹åº”çš„å±å¹•åæ ‡
            screen_coords = self.tcp_to_screen_coords(self.current_tcp_pose[:2])
            screen_info = f"å±å¹•åæ ‡: [{screen_coords[0]}, {screen_coords[1]}]"
            cv2.putText(img, screen_info, (20, info_y + 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['current_pos'], 1)

    def start_display(self):
        """å¯åŠ¨æ˜¾ç¤ºå¾ªç¯"""
        cv2.namedWindow(self.window_name, cv2.WINDOW_AUTOSIZE)
        
        while not rospy.is_shutdown():
            try:
                display_img = self.create_display_image()
                cv2.imshow(self.window_name, display_img)
                
                key = cv2.waitKey(100) & 0xFF
                if key == ord('q') or key == 27:
                    break
                elif key == ord('s'):  # ä¿å­˜æˆªå›¾
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    cv2.imwrite(f"trajectory_prediction_{timestamp}.png", display_img)
                    rospy.loginfo("æˆªå›¾å·²ä¿å­˜")
                elif key == ord('c'):  # æ ¡å‡†æ¨¡å¼ - æ˜¾ç¤ºé¼ æ ‡åæ ‡å¯¹åº”çš„TCPåæ ‡
                    self.calibration_mode(display_img)
                    
            except Exception as e:
                rospy.logwarn(f"æ˜¾ç¤ºé”™è¯¯: {e}")
                break
        
        cv2.destroyAllWindows()

    def calibration_mode(self, img):
        """ğŸ”§ æ ¡å‡†æ¨¡å¼ - ç‚¹å‡»å±å¹•æ˜¾ç¤ºå¯¹åº”çš„TCPåæ ‡"""
        def mouse_callback(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN:
                tcp_coords = self.screen_to_tcp_coords(x, y)
                rospy.loginfo(f"å±å¹•åæ ‡ ({x}, {y}) å¯¹åº”TCPåæ ‡: ({tcp_coords[0]:.3f}, {tcp_coords[1]:.3f})")
                
                # åœ¨å›¾åƒä¸Šæ˜¾ç¤º
                cv2.circle(img, (x, y), 5, (0, 255, 255), -1)
                cv2.putText(img, f"TCP:({tcp_coords[0]:.3f},{tcp_coords[1]:.3f})", 
                           (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
                cv2.imshow(self.window_name, img)
        
        cv2.setMouseCallback(self.window_name, mouse_callback)
        rospy.loginfo("æ ¡å‡†æ¨¡å¼ï¼šç‚¹å‡»å±å¹•æŸ¥çœ‹å¯¹åº”TCPåæ ‡ï¼ŒæŒ‰ä»»æ„é”®é€€å‡º")

def main():
    """ä¸»å‡½æ•°"""
    # ğŸ”§ åœ¨è¿™é‡Œè®¾ç½®ä½ çš„å®é™…HçŸ©é˜µ
    # ç¤ºä¾‹HçŸ©é˜µï¼ˆéœ€è¦æ›¿æ¢ä¸ºä½ çš„æ ‡å®šç»“æœï¼‰
    h_matrix = np.array([
        [-944.336237, -87.4102614, -4.95230579],   # ç¼©æ”¾å’Œå¹³ç§»X
        [-62.4513781,  874.191558, 134.016380],  # ç¼©æ”¾å’Œå¹³ç§»Yï¼ˆè´Ÿå·è¡¨ç¤ºYè½´ç¿»è½¬ï¼‰
        [-0.00962922264,    -0.142556057,     1.0]     # é½æ¬¡åæ ‡
    ], dtype=np.float32)

    try:
        predictor = TrajectoryPredictor(h_matrix)
        rospy.spin()
    except rospy.ROSInterruptException:
        pass
    finally:
        cv2.destroyAllWindows()

if __name__ == '__main__':
    main()